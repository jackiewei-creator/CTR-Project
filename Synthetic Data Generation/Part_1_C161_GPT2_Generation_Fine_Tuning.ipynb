{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2410.21717"
      ],
      "metadata": {
        "id": "NlQS6WQxW6zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U transformers"
      ],
      "metadata": {
        "id": "lglMBiv4eWX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/openai-community/gpt2\n",
        "\n",
        "âš ï¸ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/openai-community/gpt2)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) ðŸ™"
      ],
      "metadata": {
        "id": "dh8wckWOeWX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use a pipeline as a high-level helper\n",
        "# from transformers import pipeline\n",
        "\n",
        "# pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")"
      ],
      "metadata": {
        "id": "w_3h0rg5eWX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load model directly\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
      ],
      "metadata": {
        "id": "cxYbrlZveWX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning: Encoding to sentences"
      ],
      "metadata": {
        "id": "j5Rgkm1ajc1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import List, Optional, Iterable\n",
        "\n",
        "# def format_value(val):\n",
        "#     \"\"\"Format values nicely for text.\"\"\"\n",
        "#     if pd.isna(val):\n",
        "#         return \"unknown\"\n",
        "#     if isinstance(val, float):\n",
        "#         return f\"{val:.3f}\".rstrip('0').rstrip('.')  # e.g. 1.23, 10\n",
        "#     return str(val)\n",
        "\n",
        "# def format_feature_name(col: str) -> str:\n",
        "#     \"\"\"Make column names more human-readable.\"\"\"\n",
        "#     return col.replace('_', ' ').lower()\n",
        "\n",
        "def row_to_sentence(\n",
        "    row: pd.Series,\n",
        "    feature_cols: List[str],\n",
        "    target_col: Optional[str] = None,\n",
        "    include_target: bool = True,\n",
        ") -> str:\n",
        "    parts = []\n",
        "\n",
        "    # features\n",
        "    for col in feature_cols:\n",
        "        val = row[col]\n",
        "        feature_text = col\n",
        "        val_text = val\n",
        "        parts.append(f\"{feature_text} is {val_text}\")\n",
        "\n",
        "    # target / label\n",
        "    if include_target and target_col is not None:\n",
        "        y = row[target_col]\n",
        "        y_text = (y)\n",
        "        parts.append(f\"target is {y_text}\")\n",
        "\n",
        "    sentence = \", \".join(parts) + \".\"\n",
        "    return sentence\n",
        "\n",
        "def encode_dataset_to_sentences(\n",
        "    df: pd.DataFrame,\n",
        "    feature_cols: List[str],\n",
        "    target_col: Optional[str] = None,\n",
        "    include_target: bool = True,\n",
        ") -> Iterable[str]:\n",
        "    for _, row in df.iterrows():\n",
        "        yield row_to_sentence(row, feature_cols, target_col, include_target)\n"
      ],
      "metadata": {
        "id": "6bwrJS1ggWjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "47d0efdf",
        "outputId": "e7cd95b6-c3db-4f60-cfe7-07a602c6f4c9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the full dataset\n",
        "full_df = pd.read_csv(\"real_train_ctgan_200k_safe27.csv\")\n",
        "\n",
        "# Randomly sample 1000 rows\n",
        "df = full_df.sample(n=1000, random_state=42) # Using random_state for reproducibility\n",
        "\n",
        "# Display the first 5 rows of the sampled DataFrame\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        creat_type_cd  f_cat_uniq  f_refresh_sum  slot_id  f_rows  f_up_sum  \\\n",
              "119737              5          10              0       53      16       132   \n",
              "72272               8          13            102       35      34       221   \n",
              "158154              7          29            205       59      41       241   \n",
              "65426               8          27            384       59      64       248   \n",
              "30074               8          22            205       63      41       267   \n",
              "\n",
              "        f_dislike_sum  f_refresh_mean  u_refreshTimes  \\\n",
              "119737             75             0.0               0   \n",
              "72272              25             3.0               3   \n",
              "158154            128             5.0               5   \n",
              "65426             133             6.0               6   \n",
              "30074             116             5.0               5   \n",
              "\n",
              "        u_newsCatInterestsST_len  ...  adv_id  task_id  inter_type_cd  \\\n",
              "119737                         5  ...   17828    18800              4   \n",
              "72272                          5  ...   11883    29699              5   \n",
              "158154                         5  ...   17440    32607              3   \n",
              "65426                          5  ...   13258    13860              5   \n",
              "30074                          5  ...   11035    33709              5   \n",
              "\n",
              "        hispace_app_tags  spread_app_id  app_second_class  \\\n",
              "119737                43            312                18   \n",
              "72272                 23            283                17   \n",
              "158154                19            175                18   \n",
              "65426                 47            246                14   \n",
              "30074                 39            350                15   \n",
              "\n",
              "        ad_click_list_v002_uniq  ad_click_list_v002_len  f_hour_cos  label  \n",
              "119737                        2                       2   -0.762527      0  \n",
              "72272                         5                       5   -0.076924      0  \n",
              "158154                        3                       3   -0.379732      0  \n",
              "65426                         5                       5   -0.849202      0  \n",
              "30074                         3                       3   -0.953396      0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70f53602-63d4-467b-9335-531f6e4ae7a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creat_type_cd</th>\n",
              "      <th>f_cat_uniq</th>\n",
              "      <th>f_refresh_sum</th>\n",
              "      <th>slot_id</th>\n",
              "      <th>f_rows</th>\n",
              "      <th>f_up_sum</th>\n",
              "      <th>f_dislike_sum</th>\n",
              "      <th>f_refresh_mean</th>\n",
              "      <th>u_refreshTimes</th>\n",
              "      <th>u_newsCatInterestsST_len</th>\n",
              "      <th>...</th>\n",
              "      <th>adv_id</th>\n",
              "      <th>task_id</th>\n",
              "      <th>inter_type_cd</th>\n",
              "      <th>hispace_app_tags</th>\n",
              "      <th>spread_app_id</th>\n",
              "      <th>app_second_class</th>\n",
              "      <th>ad_click_list_v002_uniq</th>\n",
              "      <th>ad_click_list_v002_len</th>\n",
              "      <th>f_hour_cos</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>119737</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>16</td>\n",
              "      <td>132</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>17828</td>\n",
              "      <td>18800</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>312</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.762527</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72272</th>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>102</td>\n",
              "      <td>35</td>\n",
              "      <td>34</td>\n",
              "      <td>221</td>\n",
              "      <td>25</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>11883</td>\n",
              "      <td>29699</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>283</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.076924</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158154</th>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>205</td>\n",
              "      <td>59</td>\n",
              "      <td>41</td>\n",
              "      <td>241</td>\n",
              "      <td>128</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>17440</td>\n",
              "      <td>32607</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>175</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.379732</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65426</th>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>384</td>\n",
              "      <td>59</td>\n",
              "      <td>64</td>\n",
              "      <td>248</td>\n",
              "      <td>133</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>13258</td>\n",
              "      <td>13860</td>\n",
              "      <td>5</td>\n",
              "      <td>47</td>\n",
              "      <td>246</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.849202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30074</th>\n",
              "      <td>8</td>\n",
              "      <td>22</td>\n",
              "      <td>205</td>\n",
              "      <td>63</td>\n",
              "      <td>41</td>\n",
              "      <td>267</td>\n",
              "      <td>116</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>11035</td>\n",
              "      <td>33709</td>\n",
              "      <td>5</td>\n",
              "      <td>39</td>\n",
              "      <td>350</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.953396</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70f53602-63d4-467b-9335-531f6e4ae7a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70f53602-63d4-467b-9335-531f6e4ae7a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70f53602-63d4-467b-9335-531f6e4ae7a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0d54bf7-c0d0-42f9-9675-2b8c036f20f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0d54bf7-c0d0-42f9-9675-2b8c036f20f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0d54bf7-c0d0-42f9-9675-2b8c036f20f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "3ec-PJAxQ7Z-",
        "outputId": "08fd7610-2280-462a-ebc8-581759c14702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       creat_type_cd   f_cat_uniq  f_refresh_sum      slot_id       f_rows  \\\n",
              "count      1000.0000  1000.000000     1000.00000  1000.000000  1000.000000   \n",
              "mean          7.9660    34.303000      654.27700    31.692000    96.366000   \n",
              "std           1.8959    21.053038      827.52624    17.186347    96.052038   \n",
              "min           2.0000     1.000000        0.00000    12.000000     1.000000   \n",
              "25%           8.0000    18.000000      109.50000    16.000000    32.000000   \n",
              "50%           8.0000    31.000000      405.50000    26.000000    69.000000   \n",
              "75%          10.0000    48.000000      855.00000    50.000000   125.000000   \n",
              "max          10.0000   124.000000     7488.00000    69.000000   832.000000   \n",
              "\n",
              "          f_up_sum  f_dislike_sum  f_refresh_mean  u_refreshTimes  \\\n",
              "count  1000.000000    1000.000000     1000.000000     1000.000000   \n",
              "mean    323.224000     170.033000        5.750565        5.737000   \n",
              "std     241.595389     136.217551        2.932794        2.945591   \n",
              "min       0.000000       0.000000        0.000000        0.000000   \n",
              "25%     151.000000      73.000000        4.000000        4.000000   \n",
              "50%     270.000000     139.000000        6.000000        6.000000   \n",
              "75%     438.250000     231.250000        8.000000        8.000000   \n",
              "max    1870.000000    1047.000000        9.000000        9.000000   \n",
              "\n",
              "       u_newsCatInterestsST_len  ...        adv_id       task_id  \\\n",
              "count               1000.000000  ...   1000.000000   1000.000000   \n",
              "mean                   4.778000  ...  16574.236000  23230.566000   \n",
              "std                    0.908593  ...   3968.532092   8086.931531   \n",
              "min                    0.000000  ...  10015.000000  10073.000000   \n",
              "25%                    5.000000  ...  12740.000000  15655.750000   \n",
              "50%                    5.000000  ...  16758.500000  22795.500000   \n",
              "75%                    5.000000  ...  19903.750000  30797.500000   \n",
              "max                    5.000000  ...  23517.000000  36342.000000   \n",
              "\n",
              "       inter_type_cd  hispace_app_tags  spread_app_id  app_second_class  \\\n",
              "count    1000.000000       1000.000000    1000.000000       1000.000000   \n",
              "mean        4.252000         36.655000     232.550000         18.070000   \n",
              "std         0.644136         13.161048      73.074287          4.367399   \n",
              "min         3.000000         12.000000     101.000000         13.000000   \n",
              "25%         4.000000         20.000000     162.000000         14.000000   \n",
              "50%         4.000000         43.000000     213.000000         17.000000   \n",
              "75%         5.000000         47.000000     309.000000         22.000000   \n",
              "max         5.000000         53.000000     372.000000         30.000000   \n",
              "\n",
              "       ad_click_list_v002_uniq  ad_click_list_v002_len   f_hour_cos  \\\n",
              "count              1000.000000             1000.000000  1000.000000   \n",
              "mean                  4.245000                4.245000    -0.613614   \n",
              "std                   1.290209                1.290209     0.432852   \n",
              "min                   1.000000                1.000000    -1.000000   \n",
              "25%                   4.000000                4.000000    -0.954580   \n",
              "50%                   5.000000                5.000000    -0.765859   \n",
              "75%                   5.000000                5.000000    -0.422618   \n",
              "max                   5.000000                5.000000     1.000000   \n",
              "\n",
              "             label  \n",
              "count  1000.000000  \n",
              "mean      0.019000  \n",
              "std       0.136593  \n",
              "min       0.000000  \n",
              "25%       0.000000  \n",
              "50%       0.000000  \n",
              "75%       0.000000  \n",
              "max       1.000000  \n",
              "\n",
              "[8 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6868eae8-1c12-47e7-95ab-1052dec41625\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creat_type_cd</th>\n",
              "      <th>f_cat_uniq</th>\n",
              "      <th>f_refresh_sum</th>\n",
              "      <th>slot_id</th>\n",
              "      <th>f_rows</th>\n",
              "      <th>f_up_sum</th>\n",
              "      <th>f_dislike_sum</th>\n",
              "      <th>f_refresh_mean</th>\n",
              "      <th>u_refreshTimes</th>\n",
              "      <th>u_newsCatInterestsST_len</th>\n",
              "      <th>...</th>\n",
              "      <th>adv_id</th>\n",
              "      <th>task_id</th>\n",
              "      <th>inter_type_cd</th>\n",
              "      <th>hispace_app_tags</th>\n",
              "      <th>spread_app_id</th>\n",
              "      <th>app_second_class</th>\n",
              "      <th>ad_click_list_v002_uniq</th>\n",
              "      <th>ad_click_list_v002_len</th>\n",
              "      <th>f_hour_cos</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.0000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.9660</td>\n",
              "      <td>34.303000</td>\n",
              "      <td>654.27700</td>\n",
              "      <td>31.692000</td>\n",
              "      <td>96.366000</td>\n",
              "      <td>323.224000</td>\n",
              "      <td>170.033000</td>\n",
              "      <td>5.750565</td>\n",
              "      <td>5.737000</td>\n",
              "      <td>4.778000</td>\n",
              "      <td>...</td>\n",
              "      <td>16574.236000</td>\n",
              "      <td>23230.566000</td>\n",
              "      <td>4.252000</td>\n",
              "      <td>36.655000</td>\n",
              "      <td>232.550000</td>\n",
              "      <td>18.070000</td>\n",
              "      <td>4.245000</td>\n",
              "      <td>4.245000</td>\n",
              "      <td>-0.613614</td>\n",
              "      <td>0.019000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.8959</td>\n",
              "      <td>21.053038</td>\n",
              "      <td>827.52624</td>\n",
              "      <td>17.186347</td>\n",
              "      <td>96.052038</td>\n",
              "      <td>241.595389</td>\n",
              "      <td>136.217551</td>\n",
              "      <td>2.932794</td>\n",
              "      <td>2.945591</td>\n",
              "      <td>0.908593</td>\n",
              "      <td>...</td>\n",
              "      <td>3968.532092</td>\n",
              "      <td>8086.931531</td>\n",
              "      <td>0.644136</td>\n",
              "      <td>13.161048</td>\n",
              "      <td>73.074287</td>\n",
              "      <td>4.367399</td>\n",
              "      <td>1.290209</td>\n",
              "      <td>1.290209</td>\n",
              "      <td>0.432852</td>\n",
              "      <td>0.136593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.0000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>10015.000000</td>\n",
              "      <td>10073.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.0000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>109.50000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12740.000000</td>\n",
              "      <td>15655.750000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>-0.954580</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.0000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>405.50000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>270.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>16758.500000</td>\n",
              "      <td>22795.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-0.765859</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.0000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>855.00000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>438.250000</td>\n",
              "      <td>231.250000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>19903.750000</td>\n",
              "      <td>30797.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>309.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-0.422618</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.0000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>7488.00000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>832.000000</td>\n",
              "      <td>1870.000000</td>\n",
              "      <td>1047.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>23517.000000</td>\n",
              "      <td>36342.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>372.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6868eae8-1c12-47e7-95ab-1052dec41625')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6868eae8-1c12-47e7-95ab-1052dec41625 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6868eae8-1c12-47e7-95ab-1052dec41625');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8c0a656e-1877-420c-987c-35c1ac2d5e16\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c0a656e-1877-420c-987c-35c1ac2d5e16')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8c0a656e-1877-420c-987c-35c1ac2d5e16 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].astype(bool)\n",
        "target_col = df.columns[-1]\n",
        "feature_cols = [c for c in df.columns if c != target_col]"
      ],
      "metadata": {
        "id": "41W-masc2CC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_df = encode_dataset_to_sentences(df, feature_cols, target_col, include_target=True)"
      ],
      "metadata": {
        "id": "GeVyg6ME3AOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(encoded_df)[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6acCj-fW3KMn",
        "outputId": "828f9f65-2c9f-4c1e-d5b6-8fb65fb42967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['creat_type_cd is 5, f_cat_uniq is 10, f_refresh_sum is 0, slot_id is 53, f_rows is 16, f_up_sum is 132, f_dislike_sum is 75, f_refresh_mean is 0.0, u_refreshTimes is 0, u_newsCatInterestsST_len is 5, f_up_mean is 8.25, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 5, f_entities_len_mean is 4.875, f_dislike_mean is 4.6875, f_browser_life is 17.0, adv_prim_id is 1036, device_size is 2117, adv_id is 17828, task_id is 18800, inter_type_cd is 4, hispace_app_tags is 43, spread_app_id is 312, app_second_class is 18, ad_click_list_v002_uniq is 2, ad_click_list_v002_len is 2, f_hour_cos is -0.7625272039063882, target is False.',\n",
              " 'creat_type_cd is 8, f_cat_uniq is 13, f_refresh_sum is 102, slot_id is 35, f_rows is 34, f_up_sum is 221, f_dislike_sum is 25, f_refresh_mean is 3.0, u_refreshTimes is 3, u_newsCatInterestsST_len is 5, f_up_mean is 6.5, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 4, f_entities_len_mean is 4.941176470588236, f_dislike_mean is 0.7352941176470589, f_browser_life is 17.0, adv_prim_id is 1771, device_size is 2117, adv_id is 11883, task_id is 29699, inter_type_cd is 5, hispace_app_tags is 23, spread_app_id is 283, app_second_class is 17, ad_click_list_v002_uniq is 5, ad_click_list_v002_len is 5, f_hour_cos is -0.0769237541944633, target is False.',\n",
              " 'creat_type_cd is 7, f_cat_uniq is 29, f_refresh_sum is 205, slot_id is 59, f_rows is 41, f_up_sum is 241, f_dislike_sum is 128, f_refresh_mean is 5.0, u_refreshTimes is 5, u_newsCatInterestsST_len is 5, f_up_mean is 5.878048780487805, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 5, f_entities_len_mean is 3.5365853658536586, f_dislike_mean is 3.1219512195121952, f_browser_life is 17.0, adv_prim_id is 1920, device_size is 1555, adv_id is 17440, task_id is 32607, inter_type_cd is 3, hispace_app_tags is 19, spread_app_id is 175, app_second_class is 18, ad_click_list_v002_uniq is 3, ad_click_list_v002_len is 3, f_hour_cos is -0.3797318394855498, target is False.',\n",
              " 'creat_type_cd is 8, f_cat_uniq is 27, f_refresh_sum is 384, slot_id is 59, f_rows is 64, f_up_sum is 248, f_dislike_sum is 133, f_refresh_mean is 6.0, u_refreshTimes is 6, u_newsCatInterestsST_len is 5, f_up_mean is 3.875, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 5, f_entities_len_mean is 4.59375, f_dislike_mean is 2.078125, f_browser_life is 17.0, adv_prim_id is 1314, device_size is 1555, adv_id is 13258, task_id is 13860, inter_type_cd is 5, hispace_app_tags is 47, spread_app_id is 246, app_second_class is 14, ad_click_list_v002_uniq is 5, ad_click_list_v002_len is 5, f_hour_cos is -0.849202181526579, target is False.',\n",
              " 'creat_type_cd is 8, f_cat_uniq is 22, f_refresh_sum is 205, slot_id is 63, f_rows is 41, f_up_sum is 267, f_dislike_sum is 116, f_refresh_mean is 5.0, u_refreshTimes is 5, u_newsCatInterestsST_len is 5, f_up_mean is 6.512195121951219, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 5, f_entities_len_mean is 4.609756097560975, f_dislike_mean is 2.8292682926829267, f_browser_life is 17.0, adv_prim_id is 1812, device_size is 2401, adv_id is 11035, task_id is 33709, inter_type_cd is 5, hispace_app_tags is 39, spread_app_id is 350, app_second_class is 15, ad_click_list_v002_uniq is 3, ad_click_list_v002_len is 3, f_hour_cos is -0.9533963920549304, target is False.']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning: Permuting predictor variables"
      ],
      "metadata": {
        "id": "8sLhVNFblgcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def row_to_sentence_with_permutation(\n",
        "    row: pd.Series,\n",
        "    feature_cols: List[str],\n",
        "    target_col: Optional[str] = None,\n",
        "    include_target: bool = True,\n",
        "    permute_features: bool = False,\n",
        ") -> str:\n",
        "    cols = feature_cols.copy()\n",
        "    if permute_features:\n",
        "        random.shuffle(cols)\n",
        "\n",
        "    parts = []\n",
        "    for col in cols:\n",
        "        val = row[col]\n",
        "        feature_text = col\n",
        "        val_text = val\n",
        "        parts.append(f\"{feature_text} is {val_text}\")\n",
        "\n",
        "    if include_target and target_col is not None:\n",
        "        y = row[target_col]\n",
        "        y_text = y\n",
        "        parts.append(f\"target is {y_text}\")\n",
        "\n",
        "    return \", \".join(parts) + \".\"\n",
        "\n",
        "def build_Dprime_real(df, feature_cols, target_col):\n",
        "    sentences = []\n",
        "    for _, row in df.iterrows():\n",
        "        s  = row_to_sentence_with_permutation(row, feature_cols, target_col,\n",
        "                                              include_target=True,\n",
        "                                              permute_features=False)\n",
        "        s_prime = row_to_sentence_with_permutation(row, feature_cols, target_col,\n",
        "                                                   include_target=True,\n",
        "                                                   permute_features=True)\n",
        "        sentences.append(s)\n",
        "        sentences.append(s_prime)\n",
        "    return sentences\n"
      ],
      "metadata": {
        "id": "0gvhN1ckldd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dprime = build_Dprime_real(df, feature_cols, target_col)"
      ],
      "metadata": {
        "id": "XA1FqtsI3G1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dprime[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iG0he-qAvS_",
        "outputId": "8481c75a-bb0f-4b8d-cd10-4dd88afc252a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['creat_type_cd is 5, f_cat_uniq is 10, f_refresh_sum is 0, slot_id is 53, f_rows is 16, f_up_sum is 132, f_dislike_sum is 75, f_refresh_mean is 0.0, u_refreshTimes is 0, u_newsCatInterestsST_len is 5, f_up_mean is 8.25, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 5, f_entities_len_mean is 4.875, f_dislike_mean is 4.6875, f_browser_life is 17.0, adv_prim_id is 1036, device_size is 2117, adv_id is 17828, task_id is 18800, inter_type_cd is 4, hispace_app_tags is 43, spread_app_id is 312, app_second_class is 18, ad_click_list_v002_uniq is 2, ad_click_list_v002_len is 2, f_hour_cos is -0.7625272039063882, target is False.',\n",
              " 'f_browser_life is 17.0, f_dislike_sum is 75, creat_type_cd is 5, f_up_sum is 132, u_feedLifeCycle is 17, f_cat_uniq is 10, inter_type_cd is 4, u_refreshTimes is 0, ad_click_list_v002_len is 2, app_second_class is 18, u_newsCatInterestsST_uniq is 5, f_refresh_sum is 0, task_id is 18800, u_newsCatInterestsST_len is 5, f_hour_cos is -0.7625272039063882, hispace_app_tags is 43, slot_id is 53, spread_app_id is 312, f_refresh_mean is 0.0, adv_prim_id is 1036, device_size is 2117, f_up_mean is 8.25, f_dislike_mean is 4.6875, ad_click_list_v002_uniq is 2, adv_id is 17828, f_entities_len_mean is 4.875, f_rows is 16, target is False.',\n",
              " 'creat_type_cd is 8, f_cat_uniq is 13, f_refresh_sum is 102, slot_id is 35, f_rows is 34, f_up_sum is 221, f_dislike_sum is 25, f_refresh_mean is 3.0, u_refreshTimes is 3, u_newsCatInterestsST_len is 5, f_up_mean is 6.5, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 4, f_entities_len_mean is 4.941176470588236, f_dislike_mean is 0.7352941176470589, f_browser_life is 17.0, adv_prim_id is 1771, device_size is 2117, adv_id is 11883, task_id is 29699, inter_type_cd is 5, hispace_app_tags is 23, spread_app_id is 283, app_second_class is 17, ad_click_list_v002_uniq is 5, ad_click_list_v002_len is 5, f_hour_cos is -0.0769237541944633, target is False.',\n",
              " 'f_up_sum is 221, f_dislike_sum is 25, u_refreshTimes is 3, ad_click_list_v002_len is 5, u_newsCatInterestsST_uniq is 4, hispace_app_tags is 23, f_entities_len_mean is 4.941176470588236, creat_type_cd is 8, f_dislike_mean is 0.7352941176470589, f_refresh_mean is 3.0, adv_id is 11883, slot_id is 35, f_refresh_sum is 102, f_hour_cos is -0.0769237541944633, f_browser_life is 17.0, f_rows is 34, ad_click_list_v002_uniq is 5, task_id is 29699, u_newsCatInterestsST_len is 5, spread_app_id is 283, app_second_class is 17, inter_type_cd is 5, adv_prim_id is 1771, f_cat_uniq is 13, f_up_mean is 6.5, u_feedLifeCycle is 17, device_size is 2117, target is False.',\n",
              " 'creat_type_cd is 7, f_cat_uniq is 29, f_refresh_sum is 205, slot_id is 59, f_rows is 41, f_up_sum is 241, f_dislike_sum is 128, f_refresh_mean is 5.0, u_refreshTimes is 5, u_newsCatInterestsST_len is 5, f_up_mean is 5.878048780487805, u_feedLifeCycle is 17, u_newsCatInterestsST_uniq is 5, f_entities_len_mean is 3.5365853658536586, f_dislike_mean is 3.1219512195121952, f_browser_life is 17.0, adv_prim_id is 1920, device_size is 1555, adv_id is 17440, task_id is 32607, inter_type_cd is 3, hispace_app_tags is 19, spread_app_id is 175, app_second_class is 18, ad_click_list_v002_uniq is 3, ad_click_list_v002_len is 3, f_hour_cos is -0.3797318394855498, target is False.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning GPT2"
      ],
      "metadata": {
        "id": "hNIzN53HooTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U transformers datasets accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0XJSlSoKnAz7",
        "outputId": "c5f6deff-0621-4628-e579-7c3c7afc7c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, transformers, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.2\n",
            "    Uninstalling transformers-4.57.2:\n",
            "      Successfully uninstalled transformers-4.57.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 pyarrow-22.0.0 transformers-4.57.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "687187f5c03441b998e3adcc9dfe003a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "JxBuuNDspJix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_dict({\"text\": Dprime})\n",
        "\n",
        "# Optionally split train/validation\n",
        "dataset = dataset.train_test_split(test_size=0.05, shuffle=True, seed=42)\n",
        "train_ds = dataset[\"train\"]\n",
        "eval_ds  = dataset[\"test\"]\n"
      ],
      "metadata": {
        "id": "IDozcYbVpOfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"  # or \"gpt2-medium\", etc.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n"
      ],
      "metadata": {
        "id": "m_oEoP-7pRUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "12ba5760c5794c2ebff26d42151df955",
            "cb584af4c72c46099201231e20a640be",
            "49df2540c026476998106133514d4b16",
            "83d30390223249e6b7a9fcca85d511be",
            "16d7bd1027694ca8859b96a8e3587c33",
            "68f3b886fb494cebae9aa5717cf6f7ed",
            "807411e14a67444794e748ae8c73c7b1",
            "f45a493fb0fb4ffdbe104b24b49c9638",
            "68e0bd7b3876412d825113126d355622",
            "242da08436b24a1d8fdf8113ab78c106",
            "a4a69454cb8a4574b1054f2657472936",
            "218ea5fec1794f10b9d3a3572e92c941",
            "7292e3f95902427898848231bf58591b",
            "aba5cf7c854b470e84793cdf575e59f8",
            "7c1e65fdf5d54cf5b511a9d70441c367",
            "65bea6687ebb4fb28df9832781ac3ef2",
            "e91fac23918d483d8e08e4a9b6f19205",
            "59d54427c75a403f88c5db6d7c336421",
            "a302316a0ce6480682ffe7e27de79f8b",
            "1d857b60611c4be483004fa4832175fd",
            "aec1ce816ec34d56a235b613db272a2f",
            "7913697743724d56b43547cb828ea3bd",
            "61439f5d4ec34e7fa4e5c6b9af6fd513",
            "0f5dad4a0a7b442fa2799bec1cabde82",
            "657b4e41e0f843eabed27cbe25292b4a",
            "8fb6124ba22943409f58456e647b38ad",
            "88ff16689afc4accb8c827932fb484cb",
            "ef72ebfa80a849938239596c45c4220c",
            "d6b845e46b8c4ed697137119b49c6d1b",
            "ba9b39cd134748a6a79812653c5476e8",
            "8356c22931e14bf8967e320d985882cb",
            "6a2d7fd45d3144e58cc1aa6eceaab544",
            "b94558f2cff94beaad099ff9a12b9fac",
            "7ba0c38e5e7c495cbc72a6390e5de906",
            "4c21f616a6d84c678e93fd9eb9b7b040",
            "8682d98679b540fa999e760b747dc239",
            "c2f7b908083a401aa0c261ee75178573",
            "ce10019b375444aba05ec1c4e40865c6",
            "6f0d1164a7cb4a8bae7d51ed676edb04",
            "a0c8c2f0b6c442ee8cae8902b60e7415",
            "c4b4207b6d8e4409b02ec536b536c720",
            "d9a8ec3a3ca8448e9c1ae450f2ae2963",
            "4c9f12d1d2b24db3bc9e5bd8f12df8a1",
            "a1c2000be85c482b85557e2b208bf946",
            "ce1e062936364d5fa1229e0a2c60df24",
            "cc182af0bcfc4a53a8f05d54b2f9c688",
            "65e1f37dd4eb429a80aea38c060fdfe4",
            "66d2f5b6fb424404ae038a9613f32330",
            "cccab6e3daa24e98a0189e3e9cf7321a",
            "2764b2a90ff24a24a57bef1e48996db8",
            "e47543e6498b4a57946ffbda935a57a2",
            "21e05a2c11544da1a9eb4ad1e5d3ec76",
            "321de5138e374fc18ac0058014ca61b2",
            "0e9d74f5ccf6469480e9361f1435501c",
            "46a781ee4e8041be9ba9d023ee7e73d6"
          ]
        },
        "outputId": "c7e010f0-fe1a-48d7-a549-b471f53cbbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12ba5760c5794c2ebff26d42151df955"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "218ea5fec1794f10b9d3a3572e92c941"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61439f5d4ec34e7fa4e5c6b9af6fd513"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ba0c38e5e7c495cbc72a6390e5de906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce1e062936364d5fa1229e0a2c60df24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256  # or larger if your sentences are long\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "tokenized_train = train_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_eval  = eval_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "tokenized_train.set_format(type=\"torch\")\n",
        "tokenized_eval.set_format(type=\"torch\")\n"
      ],
      "metadata": {
        "id": "WdpcneS6pTXv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9a853dc3a8a54c0f98ea27ef5dc1e602",
            "1e6909d76f8a4ea8a510513b11988221",
            "59c4e976b66a4473b3098a73fff7b66f",
            "b531d57684df4da3a610ef27f2aa5387",
            "57d4bb2876a54f0d93f1ae8db0997d62",
            "baaf1608a5ce490fb46624e05688e186",
            "b93204ace6904c96a0888708054f763f",
            "0c54bba1a2d641bb85222a8d8bc1efc9",
            "66aaacdbb38641468baa1a78e51fbbc3",
            "dd552d35c68e4fbb8dc414d7324479a5",
            "4c5d3904edc941bca36000514d8cd674",
            "c01fbbb7fd81496bbbd7721de63943a4",
            "5c6c9c59bffe4caa920cf8a26f39242d",
            "fa5be0a58cb64878bc4933915d44b497",
            "bf3691e6347f4cf689988a31e1c0b444",
            "ea92878cb3ac4940b0d011e0f3ea6ca0",
            "882d436743c94b938755f03c31d53bf0",
            "144d1ad01f504c5790b117e43acf50ea",
            "9552dbaeb4ea42deae2e2c73b6d0f8c1",
            "89b94ba257ef4e61944707875cbb5764",
            "ee153ecf8ed04d4eb58c3848f312d034",
            "9eb53953d7b848739217c7e85b199ce8"
          ]
        },
        "outputId": "6deb9e75-2f81-44ca-f6f2-50f497386a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1900 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a853dc3a8a54c0f98ea27ef5dc1e602"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c01fbbb7fd81496bbbd7721de63943a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# In case vocab size changed due to adding pad token or custom tokens\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "id": "gBLhxZJXpU_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "f7de312beb0744f389ef9856186859be",
            "91e5a2e60654454db30b5f4c86464881",
            "b79c5075bf1a438ca0a85e519c1ab350",
            "519ec4e9c9d84754924aa771b5952c08",
            "c12a021a8e9b45ca9eb149373019deb5",
            "fa2d56934cb349a9aeb8749b7911a928",
            "a94716ada10f41d6a82f4fe4204a45ac",
            "2c6c8d22f5034ff5be2662e76c52744c",
            "4dc51bad0be14cd5ae21972aaf056ce2",
            "f52d1f6b1aa546fb934551fb410ed96c",
            "d801fe2ddb604cc792edbbd7fa773159",
            "17752882a0314a2bb6ac668eff5a49e1",
            "9808078d4df64e57a26c86b5650c7204",
            "e2a944cfe300416695861e3db3dddf88",
            "ffef5205d5914457a6b913703954240e",
            "38c45915b3e04a85bca527b39dd5b547",
            "0b621b0156db46d08994e780592096d8",
            "1d2b468491fc49c49c989387846cc981",
            "28dc6c8d819f4757a8b706e97f313b66",
            "96a93900bbfe43f484a41f5070ff51f0",
            "e235dfabbb1549188d37cd30c77c84c1",
            "243cd1f9c59748d3814be93986974463"
          ]
        },
        "outputId": "a20f1c67-edee-41f5-f4d8-dcd330b70b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7de312beb0744f389ef9856186859be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17752882a0314a2bb6ac668eff5a49e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,          # this makes it auto-regressive next-token prediction\n",
        ")\n"
      ],
      "metadata": {
        "id": "P2mFlpADpWxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-pred-llm\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.05,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",        # disable wandb/etc\n",
        ")\n"
      ],
      "metadata": {
        "id": "gtkPw9ltpbG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "o6KZbmQPpc1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "trainer.save_model(\"./gpt2-pred-llm\")\n",
        "tokenizer.save_pretrained(\"./gpt2-pred-llm\")"
      ],
      "metadata": {
        "id": "1Wb7kzGupemK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "45699b09-6efd-4266-baee-6ad07a523294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='357' max='357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [357/357 03:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.389500</td>\n",
              "      <td>0.802057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.814900</td>\n",
              "      <td>0.755971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.766100</td>\n",
              "      <td>0.742327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gpt2-pred-llm/tokenizer_config.json',\n",
              " './gpt2-pred-llm/special_tokens_map.json',\n",
              " './gpt2-pred-llm/vocab.json',\n",
              " './gpt2-pred-llm/merges.txt',\n",
              " './gpt2-pred-llm/added_tokens.json',\n",
              " './gpt2-pred-llm/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "print(os.listdir(\".\"))\n",
        "\n",
        "print(os.listdir(\"./gpt2-pred-llm\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22JoElhaS5_Y",
        "outputId": "2b45cb70-dce6-4bdf-8594-1b01c236eccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "['.config', 'real_train_ctgan_200k_safe27.csv', 'gpt2-pred-llm', 'sample_data']\n",
            "['tokenizer_config.json', 'training_args.bin', 'checkpoint-119', 'config.json', 'checkpoint-238', 'vocab.json', 'model.safetensors', 'tokenizer.json', 'merges.txt', 'special_tokens_map.json', 'generation_config.json', 'checkpoint-357']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8da6d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88e006d3-00c1-48ae-f818-0534fd0595cb"
      },
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "model_file_path = './gpt2-pred-llm/model.safetensors'\n",
        "\n",
        "print(f\"Downloading '{model_file_path}'...\")\n",
        "\n",
        "# Download the specific model file\n",
        "files.download(model_file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading './gpt2-pred-llm/model.safetensors'...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de4853ee-32c6-4236-adc7-3efbea56d868\", \"model.safetensors\", 497774208)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling Step"
      ],
      "metadata": {
        "id": "e1g81zzhmwJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"./gpt2-pred-llm\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir)  # will use model.safetensors\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRVnkWGLTqJv",
        "outputId": "10f0b602-26e0-4daa-fc89-1fcd6084bc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Q(condition: str, n: int, max_new_tokens: int = 64) -> list[str]:\n",
        "    inputs = tokenizer(\n",
        "        [condition] * n,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=1.0,\n",
        "            top_p=0.95,\n",
        "            top_k=50,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "\n",
        "    return tokenizer.batch_decode(out, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "myklrqoeU7s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_sentence_to_features(sentence, feature_cols):\n",
        "    sentence = sentence.strip().rstrip(\".\")\n",
        "    clauses = [c.strip() for c in sentence.split(\",\") if c.strip()]\n",
        "\n",
        "    result = {col: None for col in feature_cols}\n",
        "\n",
        "    for clause in clauses:\n",
        "        if \" is \" not in clause:\n",
        "            continue\n",
        "        key, val = clause.split(\" is \", 1)\n",
        "        key, val = key.strip(), val.strip()\n",
        "\n",
        "        if key not in result:\n",
        "            continue\n",
        "\n",
        "        if val.lower() in (\"true\", \"false\"):\n",
        "            result[key] = val.lower() == \"true\"\n",
        "        else:\n",
        "            try:\n",
        "                f = float(val)\n",
        "                result[key] = int(f) if f.is_integer() else f\n",
        "            except:\n",
        "                result[key] = val\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "TzINKlA8VM7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sample_value_from_column(df, col):\n",
        "    vals = df[col].dropna().values\n",
        "    return np.random.choice(vals)\n"
      ],
      "metadata": {
        "id": "-ZbQ-J0EVOei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def sampling_phase(df_real, feature_cols, N=1000):\n",
        "    M = len(feature_cols)\n",
        "    n_per_feature = max(1, N // M)\n",
        "\n",
        "    synthetic_rows = []\n",
        "\n",
        "    for col in feature_cols:\n",
        "        v = sample_value_from_column(df_real, col)\n",
        "        condition = f\"{col} is {v}, \"                       # partial prompt\n",
        "        gens = Q(condition, n=n_per_feature, max_new_tokens=512)\n",
        "\n",
        "        for s in gens:\n",
        "            synthetic_rows.append(parse_sentence_to_features(s, feature_cols))\n",
        "\n",
        "    # Ensure we return exactly N\n",
        "    synthetic_rows = synthetic_rows[:N]\n",
        "\n",
        "    return pd.DataFrame(synthetic_rows, columns=feature_cols)\n",
        "\n",
        "# RUN SAMPLING PHASE\n",
        "feature_cols = [c for c in df.columns if c not in (\"label\", \"target\")]\n",
        "D_fake_X = sampling_phase(df, feature_cols, N=1000)\n",
        "\n",
        "print(D_fake_X.head())\n",
        "print(D_fake_X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dkUrZOhVQ9J",
        "outputId": "fa8b7707-6603-404f-d9ea-f43b1f20286f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   creat_type_cd  f_cat_uniq  f_refresh_sum  slot_id  f_rows  f_up_sum  \\\n",
            "0            8.0        38.0          914.0     16.0   154.0       528   \n",
            "1            8.0        91.0         1028.0     58.0   105.0       569   \n",
            "2            8.0       253.0         2464.0     25.0   190.0      1197   \n",
            "3            8.0        50.0         1076.0     13.0   149.0       979   \n",
            "4            8.0        48.0         2474.0     33.0   195.0      1551   \n",
            "\n",
            "   f_dislike_sum  f_refresh_mean  u_refreshTimes  u_newsCatInterestsST_len  \\\n",
            "0          516.0             9.0             9.0                       5.0   \n",
            "1          371.0             7.0             7.0                       5.0   \n",
            "2          703.0             9.0             9.0                       5.0   \n",
            "3          495.0             8.0             8.0                       5.0   \n",
            "4         1390.0             9.0             9.0                       5.0   \n",
            "\n",
            "   ...  device_size  adv_id  task_id  inter_type_cd  hispace_app_tags  \\\n",
            "0  ...       3103.0   12382  29332.0            4.0              20.0   \n",
            "1  ...       1719.0   21358  25489.0            4.0              49.0   \n",
            "2  ...       2117.0   14903  38394.0            4.0              43.0   \n",
            "3  ...       2117.0   13672  17891.0            5.0              21.0   \n",
            "4  ...       1186.0   15029  25770.0            4.0              47.0   \n",
            "\n",
            "   spread_app_id  app_second_class  ad_click_list_v002_uniq  \\\n",
            "0          213.0              18.0                      5.0   \n",
            "1          162.0              17.0                      5.0   \n",
            "2          162.0              14.0                      5.0   \n",
            "3          257.0              18.0                      5.0   \n",
            "4          246.0              13.0                      5.0   \n",
            "\n",
            "   ad_click_list_v002_len  f_hour_cos  \n",
            "0                     5.0   -0.997958  \n",
            "1                     5.0   -0.934603  \n",
            "2                     5.0   -0.793716  \n",
            "3                     5.0   -0.926369  \n",
            "4                     5.0   -0.965925  \n",
            "\n",
            "[5 rows x 27 columns]\n",
            "(999, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Querying Step"
      ],
      "metadata": {
        "id": "1bMcwUnnca9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def features_to_prompt_for_target(row, feature_cols):\n",
        "    \"\"\"\n",
        "    Build a prompt that mirrors the training sentences in Dâ€²:\n",
        "    'col1 is v1, col2 is v2, ..., f_hour_cos is vM, target is '\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    for col in feature_cols:\n",
        "        val = row[col]\n",
        "        parts.append(f\"{col} is {val}\")\n",
        "    # Note the space after 'is' to make parsing easier\n",
        "    prompt = \", \".join(parts) + \", target is \"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "3VOezxVartAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [c for c in D_fake_X.columns if c not in (\"target\", \"label\")]\n"
      ],
      "metadata": {
        "id": "pFEUPerArtrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Q(prompt: str, n: int = 1, max_new_tokens: int = 4):\n",
        "    inputs = tokenizer(\n",
        "        [prompt] * n,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,  # just enough for \"False.\" / \"True.\"\n",
        "            do_sample=True,                 # sampling = p(Å· | xÌ‚)\n",
        "            top_k=10,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "\n",
        "    return tokenizer.batch_decode(out, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "g8cCzhDhryVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_target_bool(sentence: str):\n",
        "    \"\"\"\n",
        "    Extract True/False from text like:\n",
        "    '..., target is False.' or '..., target is True'\n",
        "    \"\"\"\n",
        "    m = re.search(r'target\\s+is\\s+([^\\s,\\.]+)', sentence, flags=re.IGNORECASE)\n",
        "    if not m:\n",
        "        return None\n",
        "\n",
        "    token = m.group(1).lower()\n",
        "    if token == \"true\":\n",
        "        return True\n",
        "    if token == \"false\":\n",
        "        return False\n",
        "    return None  # anything else is treated as invalid\n"
      ],
      "metadata": {
        "id": "WgFsNmxrr58G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def querying_phase(D_fake_X, feature_cols):\n",
        "    # make sure we don't include label/target in the features\n",
        "    feature_cols = [c for c in feature_cols if c not in (\"label\", \"target\")]\n",
        "\n",
        "    y_hats = []\n",
        "    for _, row in D_fake_X.iterrows():\n",
        "        prompt = features_to_prompt_for_target(row, feature_cols)\n",
        "        generated = Q(prompt, n=1, max_new_tokens=4)[0]\n",
        "        yhat = parse_target_bool(generated)\n",
        "        y_hats.append(yhat)\n",
        "\n",
        "    result = D_fake_X.copy()\n",
        "    result[\"target\"] = y_hats\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "C3-XZvdrrz8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = D_fake_X.iloc[0]\n",
        "prompt = features_to_prompt_for_target(row, feature_cols)\n",
        "print(\"PROMPT:\\n\", prompt)\n",
        "\n",
        "generated = Q(prompt, n=1, max_new_tokens=4)[0]\n",
        "print(\"\\nGENERATED:\\n\", generated)\n",
        "\n",
        "print(\"\\nPARSED TARGET:\", parse_target_bool(generated))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX3oiaACr2T9",
        "outputId": "979b37f5-85c6-4187-91c7-25242e6aec7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT:\n",
            " creat_type_cd is 8.0, f_cat_uniq is 38.0, f_refresh_sum is 914.0, slot_id is 16.0, f_rows is 154.0, f_up_sum is 528, f_dislike_sum is 516.0, f_refresh_mean is 9.0, u_refreshTimes is 9.0, u_newsCatInterestsST_len is 5.0, f_up_mean is 5.673333333333333, u_feedLifeCycle is 17.0, u_newsCatInterestsST_uniq is 5.0, f_entities_len_mean is 4.86666666666665, f_dislike_mean is 1.353535353535365, f_browser_life is 17.0, adv_prim_id is 2066.0, device_size is 3103.0, adv_id is 12382, task_id is 29332.0, inter_type_cd is 4.0, hispace_app_tags is 20.0, spread_app_id is 213.0, app_second_class is 18.0, ad_click_list_v002_uniq is 5.0, ad_click_list_v002_len is 5.0, f_hour_cos is -0.9979581612609536, target is \n",
            "\n",
            "GENERATED:\n",
            " creat_type_cd is 8.0, f_cat_uniq is 38.0, f_refresh_sum is 914.0, slot_id is 16.0, f_rows is 154.0, f_up_sum is 528, f_dislike_sum is 516.0, f_refresh_mean is 9.0, u_refreshTimes is 9.0, u_newsCatInterestsST_len is 5.0, f_up_mean is 5.673333333333333, u_feedLifeCycle is 17.0, u_newsCatInterestsST_uniq is 5.0, f_entities_len_mean is 4.86666666666665, f_dislike_mean is 1.353535353535365, f_browser_life is 17.0, adv_prim_id is 2066.0, device_size is 3103.0, adv_id is 12382, task_id is 29332.0, inter_type_cd is 4.0, hispace_app_tags is 20.0, spread_app_id is 213.0, app_second_class is 18.0, ad_click_list_v002_uniq is 5.0, ad_click_list_v002_len is 5.0, f_hour_cos is -0.9979581612609536, target is vernus, f\n",
            "\n",
            "PARSED TARGET: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row = D_fake_X.iloc[0]\n",
        "prompt = features_to_prompt_for_target(row, feature_cols)\n",
        "print(\"PROMPT:\\n\", prompt)\n",
        "\n",
        "generated = Q(prompt, n=1, max_new_tokens=4)[0]\n",
        "print(\"\\nGENERATED:\\n\", generated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EMF03OcrCa2",
        "outputId": "b9b41124-831f-488c-b7f7-a8725af72455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT:\n",
            " creat_type_cd is 8.0, f_cat_uniq is 38.0, f_refresh_sum is 914.0, slot_id is 16.0, f_rows is 154.0, f_up_sum is 528, f_dislike_sum is 516.0, f_refresh_mean is 9.0, u_refreshTimes is 9.0, u_newsCatInterestsST_len is 5.0, f_up_mean is 5.673333333333333, u_feedLifeCycle is 17.0, u_newsCatInterestsST_uniq is 5.0, f_entities_len_mean is 4.86666666666665, f_dislike_mean is 1.353535353535365, f_browser_life is 17.0, adv_prim_id is 2066.0, device_size is 3103.0, adv_id is 12382, task_id is 29332.0, inter_type_cd is 4.0, hispace_app_tags is 20.0, spread_app_id is 213.0, app_second_class is 18.0, ad_click_list_v002_uniq is 5.0, ad_click_list_v002_len is 5.0, f_hour_cos is -0.9979581612609536, target is \n",
            "\n",
            "GENERATED:\n",
            " creat_type_cd is 8.0, f_cat_uniq is 38.0, f_refresh_sum is 914.0, slot_id is 16.0, f_rows is 154.0, f_up_sum is 528, f_dislike_sum is 516.0, f_refresh_mean is 9.0, u_refreshTimes is 9.0, u_newsCatInterestsST_len is 5.0, f_up_mean is 5.673333333333333, u_feedLifeCycle is 17.0, u_newsCatInterestsST_uniq is 5.0, f_entities_len_mean is 4.86666666666665, f_dislike_mean is 1.353535353535365, f_browser_life is 17.0, adv_prim_id is 2066.0, device_size is 3103.0, adv_id is 12382, task_id is 29332.0, inter_type_cd is 4.0, hispace_app_tags is 20.0, spread_app_id is 213.0, app_second_class is 18.0, ad_click_list_v002_uniq is 5.0, ad_click_list_v002_len is 5.0, f_hour_cos is -0.9979581612609536, target is vernus_app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [c for c in D_fake_X.columns if c not in (\"label\", \"target\")]\n",
        "D_fake_full = querying_phase(D_fake_X, feature_cols)\n",
        "\n",
        "print(D_fake_full.head())\n",
        "print(D_fake_full[\"target\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTSm7-0cmVEq",
        "outputId": "9d142f7b-556e-436a-c3f8-0bc460756fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   creat_type_cd  f_cat_uniq  f_refresh_sum  slot_id  f_rows  f_up_sum  \\\n",
            "0            8.0        38.0          914.0     16.0   154.0       528   \n",
            "1            8.0        91.0         1028.0     58.0   105.0       569   \n",
            "2            8.0       253.0         2464.0     25.0   190.0      1197   \n",
            "3            8.0        50.0         1076.0     13.0   149.0       979   \n",
            "4            8.0        48.0         2474.0     33.0   195.0      1551   \n",
            "\n",
            "   f_dislike_sum  f_refresh_mean  u_refreshTimes  u_newsCatInterestsST_len  \\\n",
            "0          516.0             9.0             9.0                       5.0   \n",
            "1          371.0             7.0             7.0                       5.0   \n",
            "2          703.0             9.0             9.0                       5.0   \n",
            "3          495.0             8.0             8.0                       5.0   \n",
            "4         1390.0             9.0             9.0                       5.0   \n",
            "\n",
            "   ...  adv_id  task_id  inter_type_cd  hispace_app_tags  spread_app_id  \\\n",
            "0  ...   12382  29332.0            4.0              20.0          213.0   \n",
            "1  ...   21358  25489.0            4.0              49.0          162.0   \n",
            "2  ...   14903  38394.0            4.0              43.0          162.0   \n",
            "3  ...   13672  17891.0            5.0              21.0          257.0   \n",
            "4  ...   15029  25770.0            4.0              47.0          246.0   \n",
            "\n",
            "   app_second_class  ad_click_list_v002_uniq  ad_click_list_v002_len  \\\n",
            "0              18.0                      5.0                     5.0   \n",
            "1              17.0                      5.0                     5.0   \n",
            "2              14.0                      5.0                     5.0   \n",
            "3              18.0                      5.0                     5.0   \n",
            "4              13.0                      5.0                     5.0   \n",
            "\n",
            "   f_hour_cos  target  \n",
            "0   -0.997958    None  \n",
            "1   -0.934603    None  \n",
            "2   -0.793716    None  \n",
            "3   -0.926369    None  \n",
            "4   -0.965925    None  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conditional sampling on target variable does not work --> let's try sampling the entire row at once"
      ],
      "metadata": {
        "id": "NfvMG13ytEvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def sampling_phase_joint(df_real, feature_cols, N=1000,\n",
        "                         max_new_tokens=512,\n",
        "                         batch_size=16):\n",
        "    \"\"\"\n",
        "    Jointly sample X and target from the fine-tuned GPT-2.\n",
        "\n",
        "    df_real: real df (we only need it for column names)\n",
        "    feature_cols: columns to generate, INCLUDING 'target'\n",
        "    N: number of synthetic rows\n",
        "    \"\"\"\n",
        "\n",
        "    first_col = feature_cols[0]  # e.g. 'creat_type_cd'\n",
        "    synthetic_rows = []\n",
        "\n",
        "    while len(synthetic_rows) < N:\n",
        "        cur_n = min(batch_size, N - len(synthetic_rows))\n",
        "\n",
        "        # Simple prefix to steer generation into the row pattern\n",
        "        # You can also try \"\" or f\"{first_col} is \"\n",
        "        prompt = f\"{first_col} is\"\n",
        "        gens = Q(prompt, n=cur_n, max_new_tokens=max_new_tokens)\n",
        "\n",
        "        for s in gens:\n",
        "            row = parse_sentence_to_features(s, feature_cols)\n",
        "            synthetic_rows.append(row)\n",
        "\n",
        "    # Truncate in case we slightly over-shot\n",
        "    synthetic_rows = synthetic_rows[:N]\n",
        "    return pd.DataFrame(synthetic_rows, columns=feature_cols)\n"
      ],
      "metadata": {
        "id": "o24KdaSUttZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def parse_sentence_to_features(text: str, feature_cols):\n",
        "    \"\"\"\n",
        "    Parse 'col is val' pairs from generated text into a dict or list\n",
        "    aligned with feature_cols (including 'target').\n",
        "    \"\"\"\n",
        "    pattern = r'(\\w+)\\s+is\\s+([^\\s,\\.]+)'\n",
        "    matches = re.findall(pattern, text)\n",
        "\n",
        "    values = {col: np.nan for col in feature_cols}\n",
        "\n",
        "    for col, val in matches:\n",
        "        if col not in values:\n",
        "            continue\n",
        "\n",
        "        # convert to bool if target\n",
        "        if col == \"target\":\n",
        "            if val.lower() == \"true\":\n",
        "                values[col] = True\n",
        "            elif val.lower() == \"false\":\n",
        "                values[col] = False\n",
        "            else:\n",
        "                # malformed target â†’ leave as NaN or None\n",
        "                values[col] = None\n",
        "            continue\n",
        "\n",
        "        # numeric conversion for other columns\n",
        "        try:\n",
        "            if val.lower() == \"none\":\n",
        "                values[col] = None\n",
        "            elif \".\" in val:\n",
        "                values[col] = float(val)\n",
        "            else:\n",
        "                values[col] = int(val)\n",
        "        except ValueError:\n",
        "            # fallback: keep raw string if it can't be parsed\n",
        "            values[col] = val\n",
        "\n",
        "    # Return in column order\n",
        "    return [values[c] for c in feature_cols]\n"
      ],
      "metadata": {
        "id": "18GaMECcylW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last column is already renamed to 'target'\n",
        "# df.columns: [..., 'f_hour_cos', 'target']\n",
        "\n",
        "feature_cols = list(df.columns)  # this time INCLUDE 'target'\n",
        "\n",
        "D_fake_joint = sampling_phase_joint(df, feature_cols, N=1000)\n",
        "\n",
        "print(D_fake_joint.head())\n",
        "print(D_fake_joint[\"target\"].value_counts(dropna=False))\n",
        "print(D_fake_joint.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VmiD6zmynpX",
        "outputId": "048b8e6c-d1a2-47e9-a779-e8c4de80be01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   creat_type_cd  f_cat_uniq  f_refresh_sum  slot_id  f_rows  f_up_sum  \\\n",
            "0             10          47            514       16     144       542   \n",
            "1              8          26            682       54     121       586   \n",
            "2              8          43            686       17     114       576   \n",
            "3              8          47            818       50     136       769   \n",
            "4              8          41            614       58      96       463   \n",
            "\n",
            "   f_dislike_sum  f_refresh_mean  u_refreshTimes  u_newsCatInterestsST_len  \\\n",
            "0            619               9               9                         5   \n",
            "1            573               6               6                         5   \n",
            "2            574               7               7                         5   \n",
            "3            762               9               9                         5   \n",
            "4            372               9               9                         5   \n",
            "\n",
            "   ...  adv_id  task_id  inter_type_cd  hispace_app_tags  spread_app_id  \\\n",
            "0  ...   12073    12072              4                47            152   \n",
            "1  ...   12084    29382              4                47            246   \n",
            "2  ...   16384    18584              4                47            162   \n",
            "3  ...   17091    14753              5                43            312   \n",
            "4  ...   11752    18307              5                47            162   \n",
            "\n",
            "   app_second_class  ad_click_list_v002_uniq  ad_click_list_v002_len  \\\n",
            "0                23                        5                       5   \n",
            "1                18                        5                       5   \n",
            "2                14                        5                       5   \n",
            "3                23                        5                       5   \n",
            "4                18                        5                       5   \n",
            "\n",
            "   f_hour_cos  target  \n",
            "0           0     NaN  \n",
            "1           0     NaN  \n",
            "2           0     NaN  \n",
            "3           0     NaN  \n",
            "4           0     NaN  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "target\n",
            "NaN    1000\n",
            "Name: count, dtype: int64\n",
            "(1000, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still fails, let's try something else"
      ],
      "metadata": {
        "id": "qvh-nuFJ2Lxy"
      }
    }
  ]
}