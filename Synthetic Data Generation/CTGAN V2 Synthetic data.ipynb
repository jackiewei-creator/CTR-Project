{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9663174-5705-47c4-8df7-d41fec98a8a7",
   "metadata": {},
   "source": [
    "## 9.0 Build 50% Real + 50% CTGAN Synthetic Training Table (for CTGAN v2)\n",
    "\n",
    "In this new experiment, we investigate whether CTGAN can benefit from being trained on a *mixture* of real and synthetic data.\n",
    "\n",
    "- We reload the merged training data (`train_merged.parquet`) and rebuild the **Safe Top-27 + label** table.\n",
    "- We recreate an 80/20 stratified split at the **row level**:\n",
    "  - `df_train_real`: 80% real rows (for CTGAN training and sampling)\n",
    "  - `df_val_real`: 20% held-out real rows (for downstream evaluation)\n",
    "- We then load the previous **CTGAN synthetic 200k** table:\n",
    "  - `synthetic/ctgan_safe_top27_200k.parquet`\n",
    "- Finally, we construct a **mixed CTGAN v2 training table**:\n",
    "  - 100,000 rows sampled from **real 80% train pool**\n",
    "  - 100,000 rows sampled from **CTGAN synthetic 200k**\n",
    "  - Total = 200,000 rows, same size as the first CTGAN training table\n",
    "\n",
    "This mixed table (`df_ctgan_mix_200k`) will be used in Section 9.1 to train a **second CTGAN model (CTGAN v2)** and study how “second-generation” synthetic data behaves in terms of utility, fidelity, and privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16a9ff2-b8e9-4f74-b7ce-6115b9c93b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.0] Loaded merged train: (7675517, 68)\n",
      "[9.0] Overall CTR (label=1): 0.01552156030662169\n",
      "[9.0] Clean dataset: (7675517, 28)\n",
      "[9.0] Columns (first 10): ['creat_type_cd', 'f_cat_uniq', 'f_refresh_sum', 'slot_id', 'f_rows', 'f_up_sum', 'f_dislike_sum', 'f_refresh_mean', 'u_refreshTimes', 'u_newsCatInterestsST_len'] ...\n",
      "[9.0] df_train_real: (6140413, 28)\n",
      "[9.0] df_val_real  : (1535104, 28)\n",
      "[9.0] CTR (train_real): 0.01552159439438357 CTR (val_real): 0.01552142395564079\n",
      "[9.0] X_val_real: (1535104, 27)\n",
      "[9.0] y_val_real: (1535104,)\n",
      "[9.0] Loaded df_ctgan_syn_200k: (200000, 28)\n",
      "[9.0] CTGAN synthetic CTR: 0.046655\n",
      "\n",
      "[9.0] Mixed CTGAN v2 training table created.\n",
      "[9.0] df_ctgan_mix_200k shape: (200000, 28)\n",
      "[9.0] Mixed CTR: 0.03091\n",
      "[9.0] Real part size: 100000 | Synthetic part size: 100000\n"
     ]
    }
   ],
   "source": [
    "# === 9.0 Build 50% Real + 50% CTGAN Synthetic Training Table ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Path to the merged training data (same as previous notebooks)\n",
    "train_path = \"outputs_merged/train_merged.parquet\"\n",
    "df = pd.read_parquet(train_path)\n",
    "\n",
    "print(\"[9.0] Loaded merged train:\", df.shape)\n",
    "print(\"[9.0] Overall CTR (label=1):\", df[\"label\"].mean())\n",
    "\n",
    "# 2) Safe Top-27 feature list (must match previous CTGAN / VAE experiments)\n",
    "safe_top_feats = [\n",
    "    \"creat_type_cd\", \"f_cat_uniq\", \"f_refresh_sum\", \"slot_id\", \"f_rows\",\n",
    "    \"f_up_sum\", \"f_dislike_sum\", \"f_refresh_mean\", \"u_refreshTimes\",\n",
    "    \"u_newsCatInterestsST_len\", \"f_up_mean\", \"u_feedLifeCycle\",\n",
    "    \"u_newsCatInterestsST_uniq\", \"f_entities_len_mean\", \"f_dislike_mean\",\n",
    "    \"f_browser_life\", \"adv_prim_id\", \"device_size\", \"adv_id\", \"task_id\",\n",
    "    \"inter_type_cd\", \"hispace_app_tags\", \"spread_app_id\", \"app_second_class\",\n",
    "    \"ad_click_list_v002_uniq\", \"ad_click_list_v002_len\", \"f_hour_cos\",\n",
    "]\n",
    "\n",
    "# 3) Build the clean table: Safe Top-27 + label\n",
    "df_clean = df[safe_top_feats + [\"label\"]].copy()\n",
    "\n",
    "print(\"[9.0] Clean dataset:\", df_clean.shape)\n",
    "print(\"[9.0] Columns (first 10):\", df_clean.columns.tolist()[:10], \"...\")\n",
    "\n",
    "# 4) Row-level 80/20 split to define:\n",
    "#    - df_train_real: used for CTGAN training / sampling\n",
    "#    - df_val_real  : held-out real validation set (for utility evaluation)\n",
    "\n",
    "all_idx = df_clean.index.to_numpy()\n",
    "train_idx, val_idx = train_test_split(\n",
    "    all_idx,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=df_clean.loc[all_idx, \"label\"]\n",
    ")\n",
    "\n",
    "df_train_real = df_clean.loc[train_idx].reset_index(drop=True)\n",
    "df_val_real   = df_clean.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"[9.0] df_train_real:\", df_train_real.shape)\n",
    "print(\"[9.0] df_val_real  :\", df_val_real.shape)\n",
    "print(\"[9.0] CTR (train_real):\", df_train_real[\"label\"].mean(),\n",
    "      \"CTR (val_real):\", df_val_real[\"label\"].mean())\n",
    "\n",
    "# 5) Build X_val_real / y_val_real for later LightGBM evaluation\n",
    "X_val_real = df_val_real[safe_top_feats].copy()\n",
    "y_val_real = df_val_real[\"label\"].astype(int).copy()\n",
    "\n",
    "print(\"[9.0] X_val_real:\", X_val_real.shape)\n",
    "print(\"[9.0] y_val_real:\", y_val_real.shape)\n",
    "\n",
    "# 6) Load the first-generation CTGAN synthetic 200k table\n",
    "ctgan_syn_path = \"synthetic/ctgan_safe_top27_200k.parquet\"\n",
    "df_ctgan_syn_200k = pd.read_parquet(ctgan_syn_path)\n",
    "\n",
    "print(\"[9.0] Loaded df_ctgan_syn_200k:\", df_ctgan_syn_200k.shape)\n",
    "print(\"[9.0] CTGAN synthetic CTR:\", df_ctgan_syn_200k[\"label\"].mean())\n",
    "\n",
    "# 7) Construct a mixed training table: 50% real + 50% CTGAN synthetic\n",
    "TOTAL_MIX = 200_000\n",
    "N_REAL = TOTAL_MIX // 2\n",
    "N_SYN  = TOTAL_MIX - N_REAL\n",
    "\n",
    "real_sample = df_train_real.sample(n=N_REAL, random_state=123).reset_index(drop=True)\n",
    "syn_sample  = df_ctgan_syn_200k.sample(n=N_SYN, random_state=123).reset_index(drop=True)\n",
    "\n",
    "df_ctgan_mix_200k = pd.concat([real_sample, syn_sample], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n[9.0] Mixed CTGAN v2 training table created.\")\n",
    "print(\"[9.0] df_ctgan_mix_200k shape:\", df_ctgan_mix_200k.shape)\n",
    "print(\"[9.0] Mixed CTR:\", df_ctgan_mix_200k[\"label\"].mean())\n",
    "\n",
    "# Optional: quick sanity check on source proportions\n",
    "print(\"[9.0] Real part size:\", len(real_sample), \n",
    "      \"| Synthetic part size:\", len(syn_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a311567-4996-4a14-8822-e88ec3a7b8c2",
   "metadata": {},
   "source": [
    "## 9.1 Train CTGAN v2 on 50% Real + 50% Synthetic (CTGAN-Mix-200k)\n",
    "\n",
    "In this section we train a **second CTGAN model (CTGAN v2)** using the mixed table\n",
    "`df_ctgan_mix_200k` built in Section 9.0:\n",
    "\n",
    "- Total rows: **200,000**\n",
    "- Composition:\n",
    "  - 100,000 rows sampled from the real 80% training pool (`df_train_real`)\n",
    "  - 100,000 rows sampled from the first-generation CTGAN synthetic 200k table\n",
    "\n",
    "Training setup:\n",
    "\n",
    "- Inputs: Safe Top-27 features + binary label\n",
    "- Discrete columns:\n",
    "  - We explicitly treat **`label`** as a discrete (binary) column\n",
    "- Hyperparameters (kept consistent with the first CTGAN for comparability):\n",
    "  - `epochs = 10`\n",
    "  - `batch_size = 1024`\n",
    "  - `pac = 1`\n",
    "  - `embedding_dim = 128`, `generator_dim = (256, 256)`, `discriminator_dim = (256, 256)`\n",
    "\n",
    "The trained model is saved as:\n",
    "\n",
    "- `ctgan_safe_top27_mix200k.pkl`\n",
    "\n",
    "In later sections, we will:\n",
    "\n",
    "- **9.2** Generate a new 200k synthetic table from CTGAN v2\n",
    "- **9.3** Compare utility when training LightGBM on:\n",
    "  - 200k real only\n",
    "  - 200k CTGAN-v2 synthetic only\n",
    "  - 100k real + 100k CTGAN-v2 synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f858b7bd-7b68-41b4-8893-4b850f1f765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.1] Using ctgan.synthesizers.CTGAN\n",
      "[9.1] Mixed CTGAN training table: (200000, 28)\n",
      "[9.1] CTGAN v2 training view: (200000, 28)\n",
      "[9.1] Columns: ['creat_type_cd', 'f_cat_uniq', 'f_refresh_sum', 'slot_id', 'f_rows', 'f_up_sum', 'f_dislike_sum', 'f_refresh_mean', 'u_refreshTimes', 'u_newsCatInterestsST_len'] ...\n",
      "[9.1] Discrete columns for CTGAN v2: ['label']\n",
      "[9.1] Start training CTGAN v2 on df_ctgan_mix_200k (200k rows)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gen. (0.22) | Discrim. (-0.19): 100%|███████████| 10/10 [02:03<00:00, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.1] CTGAN v2 training finished.\n",
      "[9.1] Saved CTGAN v2 model -> models/ctgan_safe_top27_mix200k.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 9.1 Train CTGAN v2 on 50% Real + 50% Synthetic (CTGAN-Mix-200k) ===\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# --- 1) Robustly locate CTGAN class regardless of package version ---\n",
    "import ctgan\n",
    "\n",
    "CTGANClass = None\n",
    "\n",
    "# Try new-style API first\n",
    "try:\n",
    "    from ctgan.synthesizers import CTGAN as _CTGAN\n",
    "    CTGANClass = _CTGAN\n",
    "    print(\"[9.1] Using ctgan.synthesizers.CTGAN\")\n",
    "except Exception as e:\n",
    "    print(\"[9.1] ctgan.synthesizers.CTGAN not available, fallback to ctgan module:\", e)\n",
    "\n",
    "# Fallbacks for older versions\n",
    "if CTGANClass is None:\n",
    "    if hasattr(ctgan, \"CTGANSynthesizer\"):\n",
    "        CTGANClass = ctgan.CTGANSynthesizer\n",
    "        print(\"[9.1] Using ctgan.CTGANSynthesizer\")\n",
    "    elif hasattr(ctgan, \"CTGAN\"):\n",
    "        CTGANClass = ctgan.CTGAN\n",
    "        print(\"[9.1] Using ctgan.CTGAN\")\n",
    "\n",
    "if CTGANClass is None:\n",
    "    raise ImportError(\n",
    "        \"Cannot find CTGAN class in your ctgan installation. \"\n",
    "        \"Tried ctgan.synthesizers.CTGAN, ctgan.CTGANSynthesizer, ctgan.CTGAN.\"\n",
    "    )\n",
    "\n",
    "# --- 2) Safety checks: need mixed training table and feature list ---\n",
    "needed_vars = [\"df_ctgan_mix_200k\", \"safe_top_feats\"]\n",
    "for v in needed_vars:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"{v} not found. Please run Section 9.0 first.\")\n",
    "\n",
    "print(\"[9.1] Mixed CTGAN training table:\", df_ctgan_mix_200k.shape)\n",
    "\n",
    "# Use Safe Top-27 + label for training\n",
    "ctgan_cols = safe_top_feats + [\"label\"]\n",
    "df_ctgan_train_v2 = df_ctgan_mix_200k[ctgan_cols].copy()\n",
    "\n",
    "print(\"[9.1] CTGAN v2 training view:\", df_ctgan_train_v2.shape)\n",
    "print(\"[9.1] Columns:\", df_ctgan_train_v2.columns.tolist()[:10], \"...\")\n",
    "\n",
    "# Label \n",
    "discrete_columns_v2 = [\"label\"]\n",
    "print(\"[9.1] Discrete columns for CTGAN v2:\", discrete_columns_v2)\n",
    "\n",
    "# --- 3) Instantiate CTGAN v2 ---\n",
    "ctgan_v2 = CTGANClass(\n",
    "    embedding_dim=128,\n",
    "    generator_dim=(256, 256),\n",
    "    discriminator_dim=(256, 256),\n",
    "    batch_size=1024,\n",
    "    epochs=10,\n",
    "    pac=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# --- 4) Train ---\n",
    "print(\"[9.1] Start training CTGAN v2 on df_ctgan_mix_200k (200k rows)...\")\n",
    "ctgan_v2.fit(\n",
    "    df_ctgan_train_v2,\n",
    "    discrete_columns=discrete_columns_v2\n",
    ")\n",
    "print(\"[9.1] CTGAN v2 training finished.\")\n",
    "\n",
    "# --- 5) Save model ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "ctgan_v2_path = \"models/ctgan_safe_top27_mix200k.pkl\"\n",
    "\n",
    "with open(ctgan_v2_path, \"wb\") as f:\n",
    "    pickle.dump(ctgan_v2, f)\n",
    "\n",
    "print(\"[9.1] Saved CTGAN v2 model ->\", ctgan_v2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702760e4-cd90-499b-9f91-48b0a4252fa3",
   "metadata": {},
   "source": [
    "## 9.2 Generate 200k Synthetic Samples from CTGAN v2 (Mixed-Trained)\n",
    "\n",
    "In this section, we use the mixed-trained CTGAN v2 model (trained on 100k real + 100k CTGAN synthetic) to generate a fresh batch of 200,000 synthetic samples.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Load or reuse the trained `ctgan_v2` model from Section 9.1.\n",
    "2. Call the model's `sample` method to draw 200k rows with the full Safe Top-27 schema plus the label.\n",
    "3. Compute the synthetic CTR and check basic statistics.\n",
    "4. Save the new synthetic table for later utility and fidelity analysis:\n",
    "\n",
    "   - `synthetic/ctgan_v2_safe_top27_200k.parquet`\n",
    "   - `synthetic/ctgan_v2_safe_top27_200k.csv`\n",
    "\n",
    "This second synthetic batch (\"CTGAN v2 synthetic\") will be compared against:\n",
    "- the original CTGAN synthetic 200k, and\n",
    "- the mixed real+synthetic setups in subsequent utility experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb212c04-ab96-49e9-9335-d10f0adbee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.2] Using ctgan_v2 from memory.\n",
      "[9.2] Generating 200,000 synthetic rows from CTGAN v2...\n",
      "[9.2] Raw CTGAN v2 synthetic shape: (200000, 28)\n",
      "[9.2] Columns: ['creat_type_cd', 'f_cat_uniq', 'f_refresh_sum', 'slot_id', 'f_rows', 'f_up_sum', 'f_dislike_sum', 'f_refresh_mean', 'u_refreshTimes', 'u_newsCatInterestsST_len'] ...\n",
      "[9.2] CTGAN v2 synthetic CTR (label=1): 0.4185\n",
      "[9.2] Saved CTGAN v2 synthetic -> synthetic/ctgan_v2_safe_top27_200k.parquet\n",
      "[9.2] Saved CTGAN v2 synthetic -> synthetic/ctgan_v2_safe_top27_200k.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creat_type_cd</th>\n",
       "      <th>f_cat_uniq</th>\n",
       "      <th>f_refresh_sum</th>\n",
       "      <th>slot_id</th>\n",
       "      <th>f_rows</th>\n",
       "      <th>f_up_sum</th>\n",
       "      <th>f_dislike_sum</th>\n",
       "      <th>f_refresh_mean</th>\n",
       "      <th>u_refreshTimes</th>\n",
       "      <th>u_newsCatInterestsST_len</th>\n",
       "      <th>...</th>\n",
       "      <th>adv_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>inter_type_cd</th>\n",
       "      <th>hispace_app_tags</th>\n",
       "      <th>spread_app_id</th>\n",
       "      <th>app_second_class</th>\n",
       "      <th>ad_click_list_v002_uniq</th>\n",
       "      <th>ad_click_list_v002_len</th>\n",
       "      <th>f_hour_cos</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.026543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18404</td>\n",
       "      <td>19264</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>260</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.089975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>387</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>242</td>\n",
       "      <td>350</td>\n",
       "      <td>6.980751</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>17883</td>\n",
       "      <td>13882</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>168</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.885994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-4</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.049542</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>12691</td>\n",
       "      <td>23042</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.739881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.035839</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11363</td>\n",
       "      <td>21103</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>156</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.893324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>112</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>4.977116</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12849</td>\n",
       "      <td>18984</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>261</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.685563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   creat_type_cd  f_cat_uniq  f_refresh_sum  slot_id  f_rows  f_up_sum  \\\n",
       "0              3           6              1       44       1        12   \n",
       "1              3          72            387       46      12       242   \n",
       "2              3          18             -4       38       2       106   \n",
       "3             10           6              1       16       0         5   \n",
       "4              8          14            112       47       4        83   \n",
       "\n",
       "   f_dislike_sum  f_refresh_mean  u_refreshTimes  u_newsCatInterestsST_len  \\\n",
       "0             40       -0.026543               0                         0   \n",
       "1            350        6.980751               5                         5   \n",
       "2             46       -0.049542               0                         5   \n",
       "3             52       -0.035839               2                         1   \n",
       "4             47        4.977116               5                         0   \n",
       "\n",
       "   ...  adv_id  task_id  inter_type_cd  hispace_app_tags  spread_app_id  \\\n",
       "0  ...   18404    19264              4                50            260   \n",
       "1  ...   17883    13882              5                47            168   \n",
       "2  ...   12691    23042              5                39            250   \n",
       "3  ...   11363    21103              4                16            156   \n",
       "4  ...   12849    18984              4                41            261   \n",
       "\n",
       "   app_second_class  ad_click_list_v002_uniq  ad_click_list_v002_len  \\\n",
       "0                15                        5                       5   \n",
       "1                23                        5                       5   \n",
       "2                15                        5                       5   \n",
       "3                14                        1                       1   \n",
       "4                15                        5                       5   \n",
       "\n",
       "   f_hour_cos  label  \n",
       "0   -0.089975      1  \n",
       "1   -0.885994      0  \n",
       "2   -0.739881      1  \n",
       "3   -0.893324      0  \n",
       "4   -0.685563      1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 9.2 Generate 200k Synthetic Samples from CTGAN v2 ===\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Ensure we have the trained ctgan_v2 object\n",
    "if \"ctgan_v2\" not in globals():\n",
    "    # If notebook was restarted, reload from disk\n",
    "    model_path = \"models/ctgan_safe_top27_mix200k.pkl\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"{model_path} not found. Please re-run Section 9.1 to train and save ctgan_v2.\"\n",
    "        )\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        ctgan_v2 = pickle.load(f)\n",
    "    print(\"[9.2] Reloaded ctgan_v2 from disk:\", model_path)\n",
    "else:\n",
    "    print(\"[9.2] Using ctgan_v2 from memory.\")\n",
    "\n",
    "# 2) Number of synthetic rows to generate\n",
    "N_SYN_V2 = 200_000\n",
    "print(f\"[9.2] Generating {N_SYN_V2:,} synthetic rows from CTGAN v2...\")\n",
    "\n",
    "# 3) Sample from CTGAN v2\n",
    "df_ctgan_v2_syn = ctgan_v2.sample(N_SYN_V2)\n",
    "\n",
    "print(\"[9.2] Raw CTGAN v2 synthetic shape:\", df_ctgan_v2_syn.shape)\n",
    "print(\"[9.2] Columns:\", df_ctgan_v2_syn.columns.tolist()[:10], \"...\")\n",
    "\n",
    "# 4) Basic sanity checks: ensure Safe Top-27 + label all exist\n",
    "needed_cols = safe_top_feats + [\"label\"]\n",
    "missing = [c for c in needed_cols if c not in df_ctgan_v2_syn.columns]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"[9.2] Missing expected columns in CTGAN v2 output: {missing}\")\n",
    "\n",
    "# 5) Restrict to Safe Top-27 + label in a stable column order\n",
    "df_ctgan_v2_syn = df_ctgan_v2_syn[needed_cols].copy()\n",
    "\n",
    "# 6) Compute synthetic CTR\n",
    "ctr_v2 = float(df_ctgan_v2_syn[\"label\"].mean())\n",
    "print(\"[9.2] CTGAN v2 synthetic CTR (label=1):\", round(ctr_v2, 5))\n",
    "\n",
    "# 7) Create output folder\n",
    "os.makedirs(\"synthetic\", exist_ok=True)\n",
    "\n",
    "# 8) Save to Parquet and CSV\n",
    "parquet_path_v2 = \"synthetic/ctgan_v2_safe_top27_200k.parquet\"\n",
    "csv_path_v2     = \"synthetic/ctgan_v2_safe_top27_200k.csv\"\n",
    "\n",
    "df_ctgan_v2_syn.to_parquet(parquet_path_v2, index=False)\n",
    "df_ctgan_v2_syn.to_csv(csv_path_v2, index=False)\n",
    "\n",
    "print(\"[9.2] Saved CTGAN v2 synthetic ->\", parquet_path_v2)\n",
    "print(\"[9.2] Saved CTGAN v2 synthetic ->\", csv_path_v2)\n",
    "\n",
    "# 9) Quick preview\n",
    "df_ctgan_v2_syn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a526b9d-6908-48b0-ab11-1328ff7f9653",
   "metadata": {},
   "source": [
    "## 9.3 Utility Evaluation for CTGAN v2\n",
    "\n",
    "In this section, we evaluate the downstream predictive utility of the\n",
    "second CTGAN model (CTGAN v2), which was trained on a 50% real + 50%\n",
    "synthetic mixture of 200k samples.\n",
    "\n",
    "We consider two training setups, both evaluated on the held-out real\n",
    "validation set (`X_val_real`, `y_val_real`):\n",
    "\n",
    "1. **CTGAN v2 synthetic only (200k)**  \n",
    "   - Train LightGBM on 200,000 rows generated by CTGAN v2  \n",
    "   - Test on the real validation set\n",
    "\n",
    "2. **Mixed 100k real + 100k CTGAN v2 synthetic**  \n",
    "   - Train LightGBM on 100,000 real rows (from the original training split)\n",
    "     plus 100,000 CTGAN v2 synthetic rows  \n",
    "   - Test on the same real validation set\n",
    "\n",
    "These experiments show whether the second-round CTGAN training\n",
    "(“bootstrapping” on synthetic data) improves or degrades predictive\n",
    "performance compared with using real data alone or first-round CTGAN\n",
    "samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4f25034-0631-4fa9-a691-55e1d4000bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CTGAN v2 synthetic only (200k → real valid)] Training LightGBM...\n",
      "[CTGAN v2 synthetic only (200k → real valid)] Train shape: (200000, 27), CTR: 0.41850\n",
      "[CTGAN v2 synthetic only (200k → real valid)] scale_pos_weight = 1.39\n",
      "[LightGBM] [Info] Number of positive: 83700, number of negative: 116300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4089\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418500 -> initscore=-0.328934\n",
      "[LightGBM] [Info] Start training from score -0.328934\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's auc: 0.981531\ttrain's average_precision: 0.976421\tvalid's auc: 0.677047\tvalid's average_precision: 0.033924\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttrain's auc: 0.953017\ttrain's average_precision: 0.942341\tvalid's auc: 0.694414\tvalid's average_precision: 0.0366645\n",
      "\n",
      "=== CTGAN v2 synthetic only (200k → real valid) @ threshold=0.50 ===\n",
      "ROC-AUC   : 0.6944\n",
      "PR-AUC    : 0.0367\n",
      "LogLoss   : 0.4612\n",
      "Accuracy  : 0.7929\n",
      "Precision : 0.0337\n",
      "Recall    : 0.4456\n",
      "F1        : 0.0626\n",
      "\n",
      "[Mixed 100k real + 100k CTGAN v2 (→ real valid)] Training LightGBM...\n",
      "[Mixed 100k real + 100k CTGAN v2 (→ real valid)] Train shape: (200000, 27), CTR: 0.21693\n",
      "[Mixed 100k real + 100k CTGAN v2 (→ real valid)] scale_pos_weight = 3.61\n",
      "[LightGBM] [Info] Number of positive: 43386, number of negative: 156614\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4118\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216930 -> initscore=-1.283647\n",
      "[LightGBM] [Info] Start training from score -1.283647\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's auc: 0.986172\ttrain's average_precision: 0.962176\tvalid's auc: 0.765555\tvalid's average_precision: 0.0792946\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttrain's auc: 0.978077\ttrain's average_precision: 0.94509\tvalid's auc: 0.770494\tvalid's average_precision: 0.0755366\n",
      "\n",
      "=== Mixed 100k real + 100k CTGAN v2 (→ real valid) @ threshold=0.50 ===\n",
      "ROC-AUC   : 0.7705\n",
      "PR-AUC    : 0.0755\n",
      "LogLoss   : 0.0990\n",
      "Accuracy  : 0.9772\n",
      "Precision : 0.1661\n",
      "Recall    : 0.1163\n",
      "F1        : 0.1368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTGAN v2 synthetic only (200k)</td>\n",
       "      <td>0.694414</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.461192</td>\n",
       "      <td>0.792910</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>0.445629</td>\n",
       "      <td>0.062617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mixed 100k real + 100k CTGAN v2</td>\n",
       "      <td>0.770494</td>\n",
       "      <td>0.075537</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>0.977219</td>\n",
       "      <td>0.166107</td>\n",
       "      <td>0.116339</td>\n",
       "      <td>0.136838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model   ROC-AUC    PR-AUC   LogLoss  Accuracy  \\\n",
       "0   CTGAN v2 synthetic only (200k)  0.694414  0.036664  0.461192  0.792910   \n",
       "1  Mixed 100k real + 100k CTGAN v2  0.770494  0.075537  0.099023  0.977219   \n",
       "\n",
       "   Precision    Recall        F1  \n",
       "0   0.033674  0.445629  0.062617  \n",
       "1   0.166107  0.116339  0.136838  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 9.3 Utility: CTGAN v2 synthetic only vs Mixed 100k real + 100k v2 ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Safety checks\n",
    "needed = [\"safe_top_feats\", \"df_train_real\", \"X_val_real\", \"y_val_real\"]\n",
    "for v in needed:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"{v} not found. Please run Section 9.0 first.\")\n",
    "\n",
    "\n",
    "def evaluate_lgb(train_X, train_y, valid_X, valid_y, title):\n",
    "    \"\"\"\n",
    "    Train a LightGBM model and evaluate on the real validation set.\n",
    "    \"\"\"\n",
    "    pos_rate = train_y.mean()\n",
    "    scale_pos_weight = (1.0 - pos_rate) / pos_rate\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": [\"auc\", \"average_precision\"],\n",
    "        \"learning_rate\": 0.08,\n",
    "        \"num_leaves\": 127,\n",
    "        \"max_depth\": -1,\n",
    "        \"min_child_samples\": 100,\n",
    "        \"subsample\": 0.8,\n",
    "        \"subsample_freq\": 1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"lambda_l2\": 1.0,\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    dvalid = lgb.Dataset(valid_X, label=valid_y, reference=dtrain)\n",
    "\n",
    "    print(f\"\\n[{title}] Training LightGBM...\")\n",
    "    print(f\"[{title}] Train shape: {train_X.shape}, CTR: {train_y.mean():.5f}\")\n",
    "    print(f\"[{title}] scale_pos_weight = {scale_pos_weight:.2f}\")\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=2000,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=100),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Predict on the real validation set\n",
    "    y_proba = model.predict(valid_X, num_iteration=model.best_iteration)\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        \"ROC-AUC\": roc_auc_score(valid_y, y_proba),\n",
    "        \"PR-AUC\": average_precision_score(valid_y, y_proba),\n",
    "        \"LogLoss\": log_loss(valid_y, y_proba),\n",
    "        \"Accuracy\": accuracy_score(valid_y, y_pred),\n",
    "        \"Precision\": precision_score(valid_y, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(valid_y, y_pred),\n",
    "        \"F1\": f1_score(valid_y, y_pred),\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== {title} @ threshold=0.50 ===\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:<10s}: {v:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) CTGAN v2 synthetic only (200k)\n",
    "# ---------------------------------------------------------\n",
    "df_ctgan_v2 = pd.read_parquet(\"synthetic/ctgan_v2_safe_top27_200k.parquet\")\n",
    "X_syn_v2 = df_ctgan_v2[safe_top_feats].copy()\n",
    "y_syn_v2 = df_ctgan_v2[\"label\"].astype(int).copy()\n",
    "\n",
    "metrics_ctgan_v2_only = evaluate_lgb(\n",
    "    train_X=X_syn_v2,\n",
    "    train_y=y_syn_v2,\n",
    "    valid_X=X_val_real[safe_top_feats],\n",
    "    valid_y=y_val_real.astype(int),\n",
    "    title=\"CTGAN v2 synthetic only (200k → real valid)\",\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) Mixed 100k real + 100k CTGAN v2 synthetic\n",
    "# ---------------------------------------------------------\n",
    "real_100k = df_train_real.sample(n=100_000, random_state=42)\n",
    "syn_100k  = df_ctgan_v2.sample(n=100_000, random_state=42)\n",
    "\n",
    "X_mix = pd.concat(\n",
    "    [real_100k[safe_top_feats], syn_100k[safe_top_feats]],\n",
    "    axis=0\n",
    ").reset_index(drop=True)\n",
    "\n",
    "y_mix = pd.concat(\n",
    "    [real_100k[\"label\"].astype(int), syn_100k[\"label\"].astype(int)],\n",
    "    axis=0\n",
    ").reset_index(drop=True)\n",
    "\n",
    "metrics_ctgan_v2_mix = evaluate_lgb(\n",
    "    train_X=X_mix,\n",
    "    train_y=y_mix,\n",
    "    valid_X=X_val_real[safe_top_feats],\n",
    "    valid_y=y_val_real.astype(int),\n",
    "    title=\"Mixed 100k real + 100k CTGAN v2 (→ real valid)\",\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Put results into a small summary table\n",
    "# ---------------------------------------------------------\n",
    "summary_9_3 = pd.DataFrame([\n",
    "    {\"Model\": \"CTGAN v2 synthetic only (200k)\", **metrics_ctgan_v2_only},\n",
    "    {\"Model\": \"Mixed 100k real + 100k CTGAN v2\", **metrics_ctgan_v2_mix},\n",
    "])\n",
    "\n",
    "summary_9_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d535b00-0b26-41f9-9968-32c86920f9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
